{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     passengerid  survived  pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  name     sex   age  sibsp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     parch            ticket     fare cabin embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data\n",
    "data = pd.read_csv(\".\\\\Titanic-Dataset.csv\")\n",
    "data.columns = data.columns.str.lower()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the values in the 'sex' column\n",
    "data['sex'] = LabelEncoder().fit_transform(data['sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'embarked' column with the mode (most frequent value) and encode the values\n",
    "data['embarked'] = data['embarked'].fillna(data['embarked'].mode()[0])\n",
    "data['embarked'] = LabelEncoder().fit_transform(data['embarked'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the 'age' column with the mean age\n",
    "data['age'] = data['age'].fillna(data['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values in the 'cabin' column with 'Missing'\n",
    "data['cabin'] = data['cabin'].fillna('Missing')\n",
    "data['cabin'] = LabelEncoder().fit_transform(data['cabin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       7.2500\n",
       "1      71.2833\n",
       "2       7.9250\n",
       "3      53.1000\n",
       "4       8.0500\n",
       "        ...   \n",
       "886    13.0000\n",
       "887    30.0000\n",
       "888    23.4500\n",
       "889    30.0000\n",
       "890     7.7500\n",
       "Name: fare, Length: 891, dtype: float64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in missing values in the 'fare' column with the median fare\n",
    "data['fare'].fillna(data['fare'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['passengerid', 'name', 'ticket', 'cabin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in test and train data\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes\n",
    "titanic_features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_03f07_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_03f07\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_03f07_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_03f07_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_03f07_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_03f07_row0_col1\" class=\"data row0 col1\" >7876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_03f07_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_03f07_row1_col1\" class=\"data row1 col1\" >survived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_03f07_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_03f07_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_03f07_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_03f07_row3_col1\" class=\"data row3 col1\" >(712, 8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_03f07_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_03f07_row4_col1\" class=\"data row4 col1\" >(712, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_03f07_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_03f07_row5_col1\" class=\"data row5 col1\" >(498, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_03f07_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_03f07_row6_col1\" class=\"data row6 col1\" >(214, 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_03f07_row7_col0\" class=\"data row7 col0\" >Categorical features</td>\n",
       "      <td id=\"T_03f07_row7_col1\" class=\"data row7 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_03f07_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_03f07_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_03f07_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_03f07_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_03f07_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_03f07_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_03f07_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_03f07_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_03f07_row12_col0\" class=\"data row12 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_03f07_row12_col1\" class=\"data row12 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_03f07_row13_col0\" class=\"data row13 col0\" >Encoding method</td>\n",
       "      <td id=\"T_03f07_row13_col1\" class=\"data row13 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_03f07_row14_col0\" class=\"data row14 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_03f07_row14_col1\" class=\"data row14 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_03f07_row15_col0\" class=\"data row15 col0\" >Fold Number</td>\n",
       "      <td id=\"T_03f07_row15_col1\" class=\"data row15 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_03f07_row16_col0\" class=\"data row16 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_03f07_row16_col1\" class=\"data row16 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_03f07_row17_col0\" class=\"data row17 col0\" >Use GPU</td>\n",
       "      <td id=\"T_03f07_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_03f07_row18_col0\" class=\"data row18 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_03f07_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_03f07_row19_col0\" class=\"data row19 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_03f07_row19_col1\" class=\"data row19 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_03f07_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_03f07_row20_col0\" class=\"data row20 col0\" >USI</td>\n",
       "      <td id=\"T_03f07_row20_col1\" class=\"data row20 col1\" >4277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2264e7bd6f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Estimator xgboost not available. Please see docstring for list of available estimators.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[259], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Define target and setup experiment\u001b[39;00m\n\u001b[0;32m      4\u001b[0m experiment \u001b[38;5;241m=\u001b[39m setup(\n\u001b[0;32m      5\u001b[0m     data\u001b[38;5;241m=\u001b[39mtrain_data,\n\u001b[0;32m      6\u001b[0m     target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurvived\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m     categorical_features\u001b[38;5;241m=\u001b[39mtitanic_features\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m xgb \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxgboost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m tuned_xgb \u001b[38;5;241m=\u001b[39m tune_model(xgb, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(tuned_xgb)\n",
      "File \u001b[1;32mc:\\Users\\woutp\\Documents\\3AI\\Cloud AI\\Project\\CloudAI\\project_venv\\lib\\site-packages\\pycaret\\utils\\generic.py:964\u001b[0m, in \u001b[0;36mcheck_if_global_is_not_none.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m globals_d[name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n\u001b[1;32m--> 964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\woutp\\Documents\\3AI\\Cloud AI\\Project\\CloudAI\\project_venv\\lib\\site-packages\\pycaret\\classification\\functional.py:1001\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(estimator, fold, round, cross_validation, fit_kwargs, groups, probability_threshold, experiment_custom_tags, engine, verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;129m@check_if_global_is_not_none\u001b[39m(\u001b[38;5;28mglobals\u001b[39m(), _CURRENT_EXPERIMENT_DECORATOR_DICT)\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(\n\u001b[0;32m    874\u001b[0m     estimator: Union[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    886\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    887\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m    This function trains and evaluates the performance of a given estimator\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;124;03m    using cross validation. The output of this function is a score grid with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    998\u001b[0m \n\u001b[0;32m    999\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1001\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _CURRENT_EXPERIMENT\u001b[38;5;241m.\u001b[39mcreate_model(\n\u001b[0;32m   1002\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1003\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   1004\u001b[0m         \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m   1005\u001b[0m         cross_validation\u001b[38;5;241m=\u001b[39mcross_validation,\n\u001b[0;32m   1006\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   1007\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   1008\u001b[0m         probability_threshold\u001b[38;5;241m=\u001b[39mprobability_threshold,\n\u001b[0;32m   1009\u001b[0m         experiment_custom_tags\u001b[38;5;241m=\u001b[39mexperiment_custom_tags,\n\u001b[0;32m   1010\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m   1011\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1012\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m   1013\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1014\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\woutp\\Documents\\3AI\\Cloud AI\\Project\\CloudAI\\project_venv\\lib\\site-packages\\pycaret\\classification\\oop.py:1344\u001b[0m, in \u001b[0;36mClassificationExperiment.create_model\u001b[1;34m(self, estimator, fold, round, cross_validation, fit_kwargs, groups, experiment_custom_tags, probability_threshold, engine, verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_engine(estimator\u001b[38;5;241m=\u001b[39mestimator, engine\u001b[38;5;241m=\u001b[39mengine, severity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1344\u001b[0m     return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate_model(\n\u001b[0;32m   1345\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1346\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   1347\u001b[0m         \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m   1348\u001b[0m         cross_validation\u001b[38;5;241m=\u001b[39mcross_validation,\n\u001b[0;32m   1349\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   1350\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   1351\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1352\u001b[0m         experiment_custom_tags\u001b[38;5;241m=\u001b[39mexperiment_custom_tags,\n\u001b[0;32m   1353\u001b[0m         probability_threshold\u001b[38;5;241m=\u001b[39mprobability_threshold,\n\u001b[0;32m   1354\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m   1355\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1356\u001b[0m     )\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1359\u001b[0m         \u001b[38;5;66;03m# Reset the models back to the default engines\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\woutp\\Documents\\3AI\\Cloud AI\\Project\\CloudAI\\project_venv\\lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:1766\u001b[0m, in \u001b[0;36m_SupervisedExperiment.create_model\u001b[1;34m(self, estimator, fold, round, cross_validation, predict, fit_kwargs, groups, refit, probability_threshold, experiment_custom_tags, verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;66;03m# TODO improve error message\u001b[39;00m\n\u001b[0;32m   1755\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1756\u001b[0m     x\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[0;32m   1765\u001b[0m )\n\u001b[1;32m-> 1766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(\n\u001b[0;32m   1767\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1768\u001b[0m     fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   1769\u001b[0m     \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m   1770\u001b[0m     cross_validation\u001b[38;5;241m=\u001b[39mcross_validation,\n\u001b[0;32m   1771\u001b[0m     predict\u001b[38;5;241m=\u001b[39mpredict,\n\u001b[0;32m   1772\u001b[0m     fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   1773\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   1774\u001b[0m     refit\u001b[38;5;241m=\u001b[39mrefit,\n\u001b[0;32m   1775\u001b[0m     probability_threshold\u001b[38;5;241m=\u001b[39mprobability_threshold,\n\u001b[0;32m   1776\u001b[0m     experiment_custom_tags\u001b[38;5;241m=\u001b[39mexperiment_custom_tags,\n\u001b[0;32m   1777\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1778\u001b[0m     return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1780\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\woutp\\Documents\\3AI\\Cloud AI\\Project\\CloudAI\\project_venv\\lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:1341\u001b[0m, in \u001b[0;36m_SupervisedExperiment._create_model\u001b[1;34m(self, estimator, fold, round, cross_validation, predict, fit_kwargs, groups, refit, probability_threshold, experiment_custom_tags, verbose, system, add_to_model_list, X_train_data, y_train_data, metrics, display, model_only, return_train_score, error_score, **kwargs)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m estimator \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m available_estimators:\n\u001b[1;32m-> 1341\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1342\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not available. Please see docstring for list of available estimators.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1343\u001b[0m         )\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1346\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not have the required fit() method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1347\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Estimator xgboost not available. Please see docstring for list of available estimators."
     ]
    }
   ],
   "source": [
    "# Train the model with pycaret\n",
    "from pycaret.classification import *\n",
    "# Define target and setup experiment\n",
    "experiment = setup(\n",
    "    data=train_data,\n",
    "    target='survived',\n",
    "    categorical_features=titanic_features,\n",
    ")\n",
    "best = compare_models(sort = 'MAE', n_select=5)\n",
    "print(best)\n",
    "evaluate_model(best)\n",
    "save_model(best, 'pycaret_model')\n",
    "print(\"Model saved as pycaret_model.pkl!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual  Predicted\n",
      "709       1          0\n",
      "439       0          0\n",
      "840       0          0\n",
      "720       1          1\n",
      "39        1          1\n",
      "..      ...        ...\n",
      "433       0          0\n",
      "773       0          0\n",
      "25        1          0\n",
      "84        1          1\n",
      "10        1          1\n",
      "\n",
      "[179 rows x 2 columns]\n",
      "PyCaret Model Test Accuracy: 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "X_test = test_data[titanic_features]\n",
    "y_test = test_data['survived']\n",
    "X_test.head()\n",
    "# Make predictions on the test data using the PyCaret model\n",
    "pycaret_predictions = predict_model(tuned_xgb, data=X_test)\n",
    "# Add a column to indicate if the person survived or drowned\n",
    "pycaret_predictions['outcome'] = pycaret_predictions['prediction_label'].apply(lambda x: 1 if x == 1 else 0)\n",
    "pycaret_comparison = pd.DataFrame({'Actual': y_test, 'Predicted': pycaret_predictions['outcome']})\n",
    "print(pycaret_comparison)\n",
    "\n",
    "# Calculate accuracy for the PyCaret model\n",
    "pycaret_test_accuracy = accuracy_score(y_test, pycaret_predictions['outcome'])\n",
    "print(\"PyCaret Model Test Accuracy:\", pycaret_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model MSE: 0.14089399772192648\n",
      "Random Forest Model Accuracy: 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "# Train the model using a Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(train_data[titanic_features], train_data['survived'])\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary outcomes\n",
    "y_pred_rf_binary = [1 if pred >= 0.5 else 0 for pred in y_pred_rf]\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "rf_mse = mean_squared_error(y_test, y_pred_rf)\n",
    "print(\"Random Forest Model MSE:\", rf_mse)\n",
    "\n",
    "# Calculate Accuracy\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf_binary)\n",
    "print(\"Random Forest Model Accuracy:\", rf_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
